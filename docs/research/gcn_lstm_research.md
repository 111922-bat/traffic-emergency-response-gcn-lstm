# GCN+LSTM在交通流预测中的方法综述与实践蓝图(2023–2025)

## 执行摘要与关键结论

交通流预测的核心挑战在于同时刻画路网的拓扑依赖与跨时段、跨周期的动态变化。2023–2025年的研究呈现出从“静态图 + 规则时间建模”向“动态图 + 自适应时空联合”的明显转向:一方面,基于拉普拉斯矩阵潜在网络(LMLN)与自注意力生成时变邻接的动态图卷积网络(DGCN/AST-DGCN)成为主流;另一方面,时间建模从循环网络(LSTM/GRU)向并行化与长程建模能力更强的TCN/Transformer迁移,形成“GCN×TCN/Transformer”的时空并行范式。LSTM在数据量有限、对稳定性与可解释性要求较高的业务中仍具工程优势,但在极长序列与复杂依赖方面逐步让位于TCN/Transformer。混合架构上,串行(GCN→TCN/LSTM)、并行(空间/时间双塔)、以及门控/注意力融合三类模式并存,工程可落地性与鲁棒性成为选型关键。开源生态以STGCN、T-GCN、GCN_predict-Pytorch与Keras官方示例为代表,评测任务与数据切分在METR-LA、PEMS-BAY、PeMSD7等基准上逐步规范化。

实践建议(工程视角):
- 数据与任务定义:明确预测步长与多步策略;按统一切分(train/val/test)与归一化方案处理数据;确保邻接矩阵生成方式一致。
- 模型选型:小样本与稳态场景优先LSTM或其改进型;长序列与复杂依赖场景优先TCN/Transformer;空间依赖复杂且随时间变化的道路网络优先动态图GCN。
- 训练与部署:采用早停、学习率衰减与残差校正;图构建与采样策略需与在线推理延迟目标匹配;使用缓存与增量更新应对动态图时变特性。
- 评测与复现:统一指标口径与数据切分,进行显著性检验;关注跨数据集与跨时段的泛化,记录计算成本与推理延迟。

未来趋势:
- 动态图常态化与自监督/预训练结合,降低标注依赖并提升跨域泛化;
- 轻量化与知识蒸馏(时空蒸馏)提升边缘部署可行性;
- 跨城市迁移学习与外部因素(事件、天气)融合,增强可解释性与鲁棒性;
- 统一评测协议与可复现基准推动领域稳步前进。

上述判断基于代表性论文与开源实现的综合分析,包括动态图卷积的最新进展、时空并行建模框架,以及Keras官方教程的工程落地经验[^1][^2][^3]。

## 研究背景与问题定义

交通流预测任务通常包括速度、流量、占用率等时序变量的短时(5–15分钟)与中长期(30–60分钟)预测。城市道路与高速路网天然构成图结构:传感器或路段为节点,道路连接与距离相似性为边,特征在图上沿拓扑传播并随时间演化。核心挑战在于:
- 空间依赖:邻接与远程拓扑影响并存,静态邻接难以反映拥堵传播与事件驱动的时变关系;
- 时间依赖:周期(日/周)与趋势并存,多尺度动态叠加;
- 跨时空耦合:空间结构变化与时间动态相互强化,需联合建模;
- 外部因素:事件、天气、节假日等对时空相关性与分布产生显著影响。

数据与场景:
- 传感器网络:环路检测器等设备采集的连续时序数据;
- 路网拓扑:道路连接关系与距离、方向等属性;
- 预测任务:单步与多步预测,短期更关注平滑性与及时性,中长期更关注趋势与周期保持。

## 方法总览与问题分解

交通流预测方法从统计与机器学习演进至深度学习。传统方法如历史平均(HA)与ARIMA依赖平稳性与线性假设,难以应对非线性与跨周期复杂性。深度学习引入CNN/RNN后,开始并行或串行地刻画空间与时间依赖。进一步,图卷积网络(GCN)将卷积扩展至非欧空间,适配路网拓扑;时间维度则从LSTM/GRU扩展到TCN与Transformer,提升长程依赖与并行化能力。

时空建模范式:
- 串行:空间卷积(GCN)后接时间卷积或循环单元(TCN/LSTM),强调“空间→时间”的信息流;
- 并行:空间支路(GCN)与时间支路(TCN/LSTM/Transformer)分别建模后融合,强调多视角互补;
- 动态图:通过LMLN或自注意力生成时变邻接,刻画路网结构的时变性与不确定性;
- 注意力融合:在时空维度进行加权聚合,突出关键节点与关键时段。

为便于整体把握,下表对主流范式进行对比。

表1 时空建模范式对比(输入→空间模块→时间模块→融合→输出)

| 范式 | 输入 | 空间模块 | 时间模块 | 融合策略 | 输出 | 代表工作 |
|---|---|---|---|---|---|---|
| 串行(GCN→TCN/LSTM) | 历史张量 X: [L, N, C] | GCN/ChebNet | TCN或LSTM/GRU | 残差/拼接 | 单/多步预测 | STGCN[^4]、T-GCN[^5] |
| 并行(空间/时间双塔) | 历史张量与邻接 | GCN支路 | TCN/LSTM/Transformer支路 | 注意力/门控 | 单/多步预测 | GraphWaveNet[^6] |
| 动态图(时变邻接) | 节点嵌入 | LMLN/自注意力生成A(t) | TCN/LSTM/GRU | 周期/趋势联合 | 单/多步预测 | DGCN[^7]、AST-DGCN[^8] |
| 注意力融合 | 历史张量 | GCN + 空间注意力 | TCN/LSTM + 时间注意力 | 跨维度注意力 | 单/多步预测 | ASTGCN[^9] |

上述范式在开源实现与教程中均有体现,工程复现路径清晰[^4][^5][^6][^10]。

## GCN在交通路网建模的最新进展(空间特征提取)

静态图阶段以固定邻接(基于距离或连接)为主,难以适应路网功能的时变性。动态图通过数据驱动生成时变邻接,显著提升空间依赖刻画的灵活性与鲁棒性。代表性方法包括:
- DGCN:提出拉普拉斯矩阵潜在网络(LMLN),从数据中估计动态拉普拉斯序列;结合时间卷积、图时域卷积与时间注意力,系统性融合近期、日周期、周周期信息,在PeMSD4/PeMSD8与城市道路数据上显著优于ASTGCN[^7]。
- AST-DGCN:采用编码器-解码器结构与双层残差校正,通过节点嵌入与自注意力生成每个时间步不同的邻接矩阵,并与GRU进行时空联合建模,在RMSE/MAE/MAPE上明显优于ARIMA、LSTM与STGCN[^8]。
- GraphWaveNet:通过节点位置嵌入学习空间图(拉普拉斯分解),并以TCN建模时间依赖,形成时空并行架构,提升不确定性场景下的建模能力[^6]。
- STGCN与T-GCN:分别采用“GCN×时间卷积/门控”的串行与耦合方式,强调工程简洁与可复现性,适合作为基线与生产原型[^4][^5]。

表2 GCN家族方法对比(空间建模、时间建模、图构建、依赖组件、复杂度与优势)

| 方法 | 空间建模 | 时间建模 | 图构建 | 依赖组件 | 复杂度与工程性 | 优势 |
|---|---|---|---|---|---|---|
| STGCN[^4] | GCN/ChebNet | 时间卷积(TCN) | 静态邻接 | 残差、归一化 | 结构清晰、训练稳定 | 易复现、工程友好 |
| T-GCN[^5] | GCN | GRU | 静态邻接 | 门控机制 | 简洁高效 | 空间-时间耦合直观 |
| GraphWaveNet[^6] | 节点嵌入+拉普拉斯分解 | TCN | 学习得到的空间图 | 并行双塔 | 训练并行度较高 | 适合不确定性建模 |
| DGCN[^7] | GCN + LMLN | TCL/GTCL + 时间注意力 | 动态拉普拉斯序列 | 多头注意力、LSTM | 训练复杂度较高 | 动态图刻画能力强 |
| AST-DGCN[^8] | 自注意力动态图 | GRU | 时变邻接A(t) | 残差校正 | 复杂度中等 | 性能与可解释性兼顾 |

### 静态图到动态图:技术演进

早期工作依赖基于距离或道路连接的高斯核构造静态邻接,辅以切比雪夫多项式近似图卷积。该路径在工程上稳定,但对拥堵传播与事件驱动的时变相关性缺乏表达能力。动态图方法通过LMLN或自注意力从数据中直接学习时变邻接,替代固定拉普拉斯矩阵,更贴近路网实际。DGCN在PeMSD4/PeMSD8与费城城市道路数据上相较ASTGCN取得显著提升(高速场景≥8%,城市道路约5%),显示动态图的有效性[^7]。

### 动态图构建与时空联合建模

AST-DGCN以节点嵌入与自注意力生成时变邻接A(t),在编码器-解码器框架下与GRU进行联合建模,并通过双层残差校正降低累积误差。其在标准指标(RMSE/MAE/MAPE)上对ARIMA、LSTM、STGCN均表现优越,同时提供模块重要性分析,增强可解释性[^8]。DGCN通过LMLN估计动态拉普拉斯序列,配合时间卷积与注意力融合多周期信息,系统化地刻画时空耦合[^7]。

## LSTM在时序交通数据预测中的优势与改进

LSTM(长短期记忆网络)通过门控机制捕捉长程依赖,具备较强的可解释性与稳定性。在数据规模适中、标注成本较高、对平滑性与可解释性有要求的业务中,LSTM仍是工程首选。其改进路径主要包括:
- Bi-LSTM(双向LSTM):从前后文同时提取信息,提高对周期与趋势的捕捉能力;
- Stacked LSTM(堆叠LSTM):通过多层结构提升非线性表达能力;
- Attention-LSTM:引入注意力权重,聚焦关键时段,提高多步预测的稳定性与解释性。

与TCN/Transformer的对比:LSTM训练串行、推理延迟可控,但在超长序列与复杂依赖方面不及TCN(并行训练、感受野精确可控)与Transformer(全局注意力、长程依赖)。TCN/Transformer在极长序列与复杂模式识别中表现更优,但对工程资源与调参要求更高。Keras官方示例显示,在PeMSD7小规模场景下,GCN+LSTM组合能稳定收敛并取得合理MAE,体现了LSTM在工程落地与稳健性方面的价值[^3][^11]。

表3 LSTM变体对比(结构特性、适用场景、优缺点与工程实现)

| 变体 | 结构特性 | 适用场景 | 优点 | 局限 | 工程实现要点 |
|---|---|---|---|---|---|
| LSTM[^11] | 门控循环 | 中短序列、稳态 | 稳健、可解释 | 长程依赖有限 | 堆叠层数与dropout控制过拟合 |
| Bi-LSTM | 双向读取 | 周期/趋势明显 | 上下文建模强 | 训练时延增加 | 输入对齐与padding策略 |
| Stacked LSTM | 多层堆叠 | 复杂非线性 | 表达力强 | 调参复杂 | 学习率衰减与早停 |
| Attention-LSTM | 加权聚焦 | 多步预测 | 稳定性与可解释性 | 额外注意力计算 | 注意力维度与阈值设置 |

## GCN+LSTM混合架构:设计模式与融合策略

混合架构的设计需兼顾空间依赖、时间依赖与工程可落地性,主要模式包括:

- 串行堆叠(GCN→LSTM/TCN):先以GCN聚合空间特征,再由LSTM/TCN建模时序;优势在于结构清晰、训练稳定,适合作为生产基线与快速原型[^4][^5]。
- 并行双塔(空间支路×时间支路):空间支路采用GCN,时间支路采用LSTM/TCN/Transformer,融合采用注意力或门控;优势在于多视角互补与并行加速潜力[^6][^10]。
- 门控/注意力融合:在空间与时间维度引入注意力权重,动态选择关键节点与时段,提高多步预测的稳定性与解释性[^9]。
- 残差与校正:堆叠残差模块与双层残差校正(如AST-DGCN)用于抑制误差累积,提升长序列预测质量[^8]。

表4 融合策略对比(信息流、梯度路径、计算成本、稳定性与代表实现)

| 策略 | 信息流 | 梯度路径 | 计算成本 | 稳定性 | 代表实现 |
|---|---|---|---|---|---|
| 串行(GCN→LSTM/TCN) | 空间→时间 | 端到端 | 低–中 | 高 | STGCN[^4]、T-GCN[^5] |
| 并行双塔 | 空间∥时间 | 融合层回传 | 中 | 中–高 | GraphWaveNet[^6]、Keras示例[^10] |
| 注意力融合 | 空间/时间加权 | 注意力回传 | 中–高 | 高 | ASTGCN[^9] |
| 残差校正 | 跨层旁路 | 校正项回传 | 中 | 高 | AST-DGCN[^8] |

工程建议:小规模数据与稳态场景优先串行;长序列与复杂依赖场景优先并行与注意力融合;对多步预测与长程依赖要求高的场景引入残差校正与学习率调度。

## 开源代码实现与论文资源地图

开源生态为复现与落地提供了成熟路径:
- STGCN(IJCAI’18):经典时空图卷积框架,PyTorch实现与数据集齐备,适合作为基线模型与工程入门[^4]。
- T-GCN(GCN+GRU):结合图卷积与门控循环单元,结构简洁,适合实时交通预测原型[^5]。
- GCN_predict-Pytorch:覆盖GCN/GAT/ChebNet的交通流量预测实现,便于扩展与对比实验[^12]。
- Keras官方示例:提供GCN+LSTM的端到端教程与数据管道,包含PeMSD7数据、训练配置与可视化,工程落地友好[^10]。
- DGCN代码仓库:实现LMLN与动态图构建,支持多周期输入与时间注意力融合[^13]。

表5 开源仓库清单(仓库名、框架、模型类型、数据集支持、活跃度与许可)

| 仓库名 | 框架 | 模型类型 | 数据集支持 | 活跃度 | 许可 |
|---|---|---|---|---|---|
| STGCN_IJCAI-18[^4] | PyTorch | GCN+TCN | METR-LA、PeMS等 | 高 | 开源 |
| T-GCN[^5] | PyTorch | GCN+GRU | 多场景 | 高 | 开源 |
| GCN_predict-Pytorch[^12] | PyTorch | GCN/GAT/ChebNet | 交通流量 | 中 | 开源 |
| Keras示例[^10] | TensorFlow/Keras | GCN+LSTM | PeMSD7 | 高 | 开源 |
| DGCN代码[^13] | PyTorch | 动态图GCN | PeMSD4/8等 | 中 | 开源 |

## 数据集与评测协议

常用数据集与任务设置逐步规范化:
- METR-LA:洛杉矶地区207个传感器,5分钟间隔,速度数据,覆盖约4个月;常见任务为“过去12步预测未来12步”[^14]。
- PEMS-BAY:湾区传感器网络速度数据,常用于空间依赖与多步预测评测。
- PeMSD7(M/W/L/M):加州第7区数据,包含站点距离矩阵与速度时间序列;Keras示例采用工作日数据并提供采样与邻接生成策略[^10]。

评测指标:
- MAE(平均绝对误差):直观反映平均偏差;
- RMSE(均方根误差):对大误差更敏感;
- MAPE(平均绝对百分比误差):相对误差度量,零值需处理;
- R²(决定系数):拟合优度。

数据切分与归一化:
- 常见切分为train/val/test=0.6/0.2/0.2或0.5/0.2/0.3;
- 归一化建议采用Z-score或Min-Max,确保训练/验证/测试一致;
- 邻接矩阵生成:基于距离的高斯核或连接关系,参数(如sigma2、epsilon)需统一与记录[^10]。

表6 数据集对比(节点数、时间跨度、采样频率、特征维度、典型任务)

| 数据集 | 节点数 | 时间跨度 | 采样频率 | 特征维度 | 典型任务 |
|---|---|---|---|---|---|
| METR-LA[^14] | 207 | ~4个月 | 5分钟 | 速度(可扩展) | 12→12步预测 |
| PEMS-BAY | 数百 | 数月 | 5分钟 | 速度 | 多步预测 |
| PeMSD7(W_228/V_228)[^10] | 228(采样26) | 2012年5–6月工作日 | 5分钟 | 速度+距离矩阵 | 12→3步预测 |

表7 评测指标定义与注意事项

| 指标 | 定义 | 注意事项 |
|---|---|---|
| MAE | 平均绝对误差 | 对异常值不敏感,业务可解释性强 |
| RMSE | 均方根误差 | 放大预测偏差,适合关注大误差场景 |
| MAPE | 平均绝对百分比误差 | 零值导致不稳定,需平滑或阈值处理 |
| R² | 决定系数 | 衡量拟合优度,越接近1越好 |

## 性能基准与对比分析

统一评测协议下,动态图方法在多数据集上展现优势。以AST-DGCN为例,文献报告在RMSE/MAE/MAPE上对ARIMA、LSTM、STGCN具有显著优势,体现了时变图结构与时空联合建模的增益[^8]。DGCN在PeMSD4/PeMSD8与费城城市道路数据上相较ASTGCN的提升(高速≥8%,城市约5%)进一步印证动态图的普适性[^7]。Keras官方示例在PeMSD7小规模场景下,GCN+LSTM组合的MAE与naive基线接近,体现了工程可行性与训练稳定性[^10]。

表8 代表性方法在公开数据集上的指标汇总(示例)

| 方法 | 数据集 | 指标 | 性能(示例) | 备注 |
|---|---|---|---|---|
| AST-DGCN[^8] | 城市路网 | RMSE/MAE/MAPE | 32.1 / 23.4 / 9.7% | 对比ARIMA/LSTM/STGCN显著优势 |
| DGCN[^7] | PeMSD4/8 | RMSE/MAE | 优于ASTGCN ≥8% | 高速场景;城市约5%提升 |
| GCN+LSTM[^10] | PeMSD7 | MAE | ~0.1352 | 与naive接近,训练稳定 |

表9 计算成本与推理延迟对比(相对量纲)

| 方法 | 训练时间 | 推理延迟 | 资源消耗 | 备注 |
|---|---|---|---|---|
| STGCN[^4] | 中 | 低 | 中 | 结构清晰,工程友好 |
| T-GCN[^5] | 中 | 低 | 中 | GCN+GRU简洁高效 |
| GraphWaveNet[^6] | 中–高 | 中 | 中–高 | 并行训练,TCN加速 |
| DGCN[^7] | 高 | 中 | 高 | 动态图估计与注意力融合 |
| AST-DGCN[^8] | 中 | 中 | 中 | 残差校正增加少量开销 |
| GCN+LSTM[^10] | 中 | 低 | 中 | Keras示例,工程落地友好 |

注:以上为相对量纲对比,具体数值依赖实现与硬件环境。Keras示例提供端到端工程参考,含数据管道与训练配置[^10]。

## 工程落地指南(数据、模型、训练与部署)

数据管线:
- 滑动窗口:按统一窗口长度(如12步)构造样本,保证时间对齐;
- 归一化:采用Z-score或Min-Max,训练/验证/测试一致;
- 邻接矩阵:基于距离或连接的核函数生成,记录参数(如sigma2、epsilon);动态图场景需缓存节点嵌入与注意力计算结果;
- 数据集切分:按0.6/0.2/0.2或0.5/0.2/0.3划分,避免泄漏。

模型构建:
- 输入张量形状管理:[batch, input_len, node, channels],确保空间与时间维度一致;
- GCN层选择:ChebNet/GCN,考虑切比雪夫阶数与归一化;
- LSTM/TCN层:根据任务选择堆叠层数与感受野大小;
- 残差与正则化:引入残差旁路、Dropout与L2正则,缓解过拟合;
- 融合策略:并行双塔的融合层采用注意力或门控,串行堆叠注意层间维度匹配。

训练技巧:
- 早停与学习率调度:监控验证集指标,防止过拟合;
- 梯度裁剪与稳定训练:动态图场景注意梯度爆炸;
- 周期输入:近期/日/周周期联合输入提升多尺度建模[^7];
- 残差校正:长序列多步预测引入校正模块降低误差累积[^8]。

部署与推理:
- 在线更新:动态图邻接的时变特性需在线更新或缓存;
- 缓存策略:节点嵌入与注意力权重可缓存并增量刷新;
- 边缘部署:轻量化模型(减少层数与通道)与蒸馏(时空蒸馏)提升可行性;
- 延迟目标:多步预测与动态图计算需与业务延迟目标匹配。

可复现建议:
- 固定随机种子与数据切分;
- 记录邻接生成参数与归一化统计;
- 统一评测协议与指标口径;
- 公开配置文件与超参数。

## 未来趋势与研究机会

- 动态图常态化与自监督/预训练结合:通过预训练学习稳健的时空表示,降低标注依赖并提升跨域泛化;
- 轻量化与知识蒸馏:以教师-学生框架进行时空蒸馏,实现模型压缩与边缘部署;
- 跨城市迁移与外部因素融合:引入事件、天气、节假日等特征,结合迁移学习提升泛化与鲁棒性;
- 评测协议统一:推动跨数据集与跨时段的统一评测,建立显著性检验与复现标准。

## 结论与实践清单

何时选型何种方法:
- 小样本与稳态任务:优先LSTM及其改进型(Attention-LSTM),工程稳健且可解释;
- 长序列与复杂依赖:优先TCN/Transformer,配合动态图GCN提升时空建模能力;
- 空间依赖复杂且时变:优先动态图GCN(DGCN/AST-DGCN),配合残差校正与多周期输入;
- 工程落地与快速原型:串行架构(GCN→LSTM/TCN)与成熟开源(STGCN/T-GCN/Keras示例)。

落地检查清单:
- 数据:窗口与切分一致、归一化与邻接参数记录完整;
- 模型:输入/输出维度匹配、层间维度与残差连接正确;
- 训练:早停与学习率调度、梯度裁剪与正则化;
- 评测:统一指标与协议、显著性检验;
- 部署:在线更新与缓存策略、延迟与资源评估。

下一步工作:
- 统一协议下的可复现实验与跨数据集评测;
- 引入外部因素与多源数据融合;
- 推进轻量化与蒸馏,完善边缘部署方案。

## 附录:术语表与实现要点

术语与符号:
- 图卷积网络(GCN):在图结构上进行卷积操作,聚合邻域信息;
- 拉普拉斯矩阵(Laplacian):图的谱表示基础,用于谱方法与动态图估计;
- 切比雪夫多项式(ChebNet):用于近似图卷积,降低计算复杂度;
- 时间卷积网络(TCN):并行化时间建模,感受野可控;
- 长短期记忆网络(LSTM):门控循环单元,捕捉长程依赖;
- 注意力机制(Attention):对关键信息加权,提升表达与可解释性;
- 编码器-解码器(Encoder-Decoder):编码时空特征并解码生成预测;
- 残差连接(Residual):旁路传递梯度,缓解深层网络退化。

实现要点:
- 张量形状:[batch, input_len, node, channels];
- 邻接矩阵生成:距离核函数与参数记录(如sigma2、epsilon);
- 归一化:训练/验证/测试一致,推荐Z-score或Min-Max;
- 训练配置:学习率、批大小、epoch、early stopping与回调。

---

## 参考文献

[^1]: 电子与信息学报:长期Transformer和自适应傅里叶变换的动态图卷积交通流预测(2025)。https://jeit.ac.cn/cn/article/doi/10.11999/JEIT241076  
[^2]: 软件学报:多视角融合的时空动态GCN城市交通流量预测(2024)。https://jos.org.cn/html/2024/4/7018.htm  
[^3]: Keras示例:使用图神经网络和LSTM进行交通预测。https://keras.org.cn/examples/timeseries/timeseries_traffic_forecasting/  
[^4]: GitHub - STGCN_IJCAI-18。https://github.com/VeritasYin/STGCN_IJCAI-18  
[^5]: GitHub - T-GCN: Temporal Graph Convolutional Network。https://github.com/lehaifeng/T-GCN  
[^6]: 知乎专栏:交通流量预测(三)--GraphWaveNet(IJCAI-19)。https://zhuanlan.zhihu.com/p/698262512  
[^7]: 知乎专栏:DGCN论文精读。https://zhuanlan.zhihu.com/p/663016070  
[^8]: AST-DGCN模型深度解析(Scientific Reports 2025解读)。https://www.xugj520.cn/archives/ast-dgcn-traffic-prediction-2.html  
[^9]: ASTGCN-Attention Based Spatial-Temporal Graph Convolutional Network(笔记)。https://dazuozcy.github.io/posts/ASTGCN/  
[^10]: Keras官方示例源码:GCN+LSTM交通预测。https://github.com/keras-team/keras-io/blob/master/examples/timeseries/timeseries_traffic_forecasting.py  
[^11]: HansPub:交通流动态预测LSTM模型设计。https://pdf.hanspub.org/CSA20231200000_59516045.pdf  
[^12]: GitHub - GCN_predict-Pytorch(交通流量预测)。https://github.com/LeronQ/GCN_predict-Pytorch  
[^13]: GitHub - DGCN代码仓库。https://github.com/guokan987/DGCN.git  
[^14]: CSDN:METR-LA数据集介绍。https://blog.csdn.net/qq_44858786/article/details/134788448  
[^15]: 知乎专栏:交通预测模型——STSGCN(AAAI 2020)+代码。https://zhuanlan.zhihu.com/p/436535209  
[^16]: IEEE T-GCN: A Temporal Graph Convolutional Network for Traffic Prediction。https://ieeexplore.ieee.org/abstract/document/8809901  
[^17]: 知乎专栏:不确定性时空图建模系列(一):Graph WaveNet。https://zhuanlan.zhihu.com/p/342466255  
[^18]: 交通速度数据集(METR-LA、PEMS-BAY、PEMSD7)。https://zhuanlan.zhihu.com/p/1932002363905933394  
[^19]: 懂AI:traffic_prediction 模型与数据集综合评估。https://www.dongaigc.com/p/aprbw/traffic_prediction

---

信息缺口说明:
- 跨数据集统一评测协议下的完整数值对比仍不足,部分来源仅提供相对改进幅度;
- 部分博客/解读类来源权威性有限,建议以论文与官方代码为准;
- LSTM变体在交通场景的系统化对比实验数据不足;
- 动态图构建的在线更新与实时推理延迟指标尚不完备;
- 外部因素(事件、天气、节假日)融合的量化收益缺少统一基准。